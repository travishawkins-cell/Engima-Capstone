{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d41045e-a07e-4069-bb88-61f66a6368c9",
   "metadata": {},
   "source": [
    "# This section has each the rotor selection, position, text and output built into the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f7582e1-2212-4fe1-a517-0bfc93baad76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enigma Machine Emulator\n",
      "==================================================\n",
      "Initial rotor positions: AAA\n",
      "\n",
      "Plaintext:  HELLO WORLD\n",
      "Ciphertext: MFNCZ BBFZM\n",
      "Final rotor positions: KAA\n",
      "\n",
      "Decoded:    HELLO WORLD\n",
      "Final rotor positions: KAA\n"
     ]
    }
   ],
   "source": [
    "class Rotor:\n",
    "    \"\"\"Represents a single Enigma rotor with its wiring and position\"\"\"\n",
    "    \n",
    "    def __init__(self, wiring, notch, ring_setting=0, position=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            wiring: String of 26 letters representing the rotor's internal wiring\n",
    "            notch: Letter(s) where rotor causes next rotor to step\n",
    "            ring_setting: Ring setting (0-25, default 0 for 'A')\n",
    "            position: Initial rotor position (0-25, default 0 for 'A')\n",
    "        \"\"\"\n",
    "        self.wiring = wiring\n",
    "        self.notch = notch\n",
    "        self.ring_setting = ring_setting\n",
    "        self.position = position\n",
    "    \n",
    "    def encode_forward(self, char_index):\n",
    "        \"\"\"Encode character passing through rotor from right to left\"\"\"\n",
    "        # Adjust for rotor position and ring setting\n",
    "        shifted = (char_index + self.position - self.ring_setting) % 26\n",
    "        # Pass through wiring\n",
    "        encoded = ord(self.wiring[shifted]) - ord('A')\n",
    "        # Adjust back\n",
    "        return (encoded - self.position + self.ring_setting) % 26\n",
    "    \n",
    "    def encode_backward(self, char_index):\n",
    "        \"\"\"Encode character passing through rotor from left to right (after reflector)\"\"\"\n",
    "        # Adjust for rotor position and ring setting\n",
    "        shifted = (char_index + self.position - self.ring_setting) % 26\n",
    "        # Find inverse mapping in wiring\n",
    "        encoded = self.wiring.index(chr(shifted + ord('A')))\n",
    "        # Adjust back\n",
    "        return (encoded - self.position + self.ring_setting) % 26\n",
    "    \n",
    "    def is_at_notch(self):\n",
    "        \"\"\"Check if rotor is at notch position (will cause next rotor to turn)\"\"\"\n",
    "        return chr(self.position + ord('A')) in self.notch\n",
    "    \n",
    "    def step(self):\n",
    "        \"\"\"Rotate the rotor by one position\"\"\"\n",
    "        self.position = (self.position + 1) % 26\n",
    "\n",
    "\n",
    "class Reflector:\n",
    "    \"\"\"Represents the Enigma reflector\"\"\"\n",
    "    \n",
    "    def __init__(self, wiring):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            wiring: String of 26 letters representing reflector pairs\n",
    "        \"\"\"\n",
    "        self.wiring = wiring\n",
    "    \n",
    "    def reflect(self, char_index):\n",
    "        \"\"\"Reflect the character back through the rotors\"\"\"\n",
    "        return ord(self.wiring[char_index]) - ord('A')\n",
    "\n",
    "\n",
    "class EnigmaMachine:\n",
    "    \"\"\"Complete Enigma machine with 3 rotors and reflector\"\"\"\n",
    "    \n",
    "    # Historical rotor wirings (Enigma I)\n",
    "    ROTOR_I = \"EKMFLGDQVZNTOWYHXUSPAIBRCJ\"\n",
    "    ROTOR_II = \"AJDKSIRUXBLHWTMCQGZNPYFVOE\"\n",
    "    ROTOR_III = \"BDFHJLCPRTXVZNYEIWGAKMUSQO\"\n",
    "    ROTOR_IV = \"ESOVPZJAYQUIRHXLNFTGKDCMWB\"\n",
    "    ROTOR_V = \"VZBRGITYUPSDNHLXAWMJQOFECK\"\n",
    "    \n",
    "    # Reflector B (most commonly used)\n",
    "    REFLECTOR_B = \"YRUHQSLDPXNGOKMIEBFZCWVJAT\"\n",
    "    \n",
    "    # Notch positions for each rotor\n",
    "    NOTCHES = {\n",
    "        'I': 'Q',    # Rotor I turns rotor II when moving from Q to R\n",
    "        'II': 'E',   # Rotor II turns rotor III when moving from E to F\n",
    "        'III': 'V',  # Rotor III turns nothing (it's the leftmost)\n",
    "        'IV': 'J',\n",
    "        'V': 'Z'\n",
    "    }\n",
    "    \n",
    "    def __init__(self, rotor_types=('I', 'II', 'III'), \n",
    "                 positions=(0, 0, 0), ring_settings=(0, 0, 0)):\n",
    "        \"\"\"\n",
    "        Initialize Enigma machine\n",
    "        \n",
    "        Args:\n",
    "            rotor_types: Tuple of 3 rotor identifiers (rightmost, middle, leftmost)\n",
    "            positions: Starting positions for each rotor (0-25 for A-Z)\n",
    "            ring_settings: Ring settings for each rotor (0-25 for A-Z)\n",
    "        \"\"\"\n",
    "        rotor_wirings = {\n",
    "            'I': self.ROTOR_I,\n",
    "            'II': self.ROTOR_II,\n",
    "            'III': self.ROTOR_III,\n",
    "            'IV': self.ROTOR_IV,\n",
    "            'V': self.ROTOR_V\n",
    "        }\n",
    "        \n",
    "        # Create rotors (right, middle, left)\n",
    "        self.rotors = [\n",
    "            Rotor(rotor_wirings[rotor_types[0]], self.NOTCHES[rotor_types[0]], \n",
    "                  ring_settings[0], positions[0]),\n",
    "            Rotor(rotor_wirings[rotor_types[1]], self.NOTCHES[rotor_types[1]], \n",
    "                  ring_settings[1], positions[1]),\n",
    "            Rotor(rotor_wirings[rotor_types[2]], self.NOTCHES[rotor_types[2]], \n",
    "                  ring_settings[2], positions[2])\n",
    "        ]\n",
    "        \n",
    "        self.reflector = Reflector(self.REFLECTOR_B)\n",
    "    \n",
    "    def step_rotors(self):\n",
    "        \"\"\"\n",
    "        Step rotors according to Enigma stepping mechanism\n",
    "        Implements the double-stepping mechanism\n",
    "        \"\"\"\n",
    "        # Check if middle rotor is at notch (double-stepping)\n",
    "        if self.rotors[1].is_at_notch():\n",
    "            self.rotors[1].step()\n",
    "            self.rotors[2].step()\n",
    "        # Check if right rotor is at notch\n",
    "        elif self.rotors[0].is_at_notch():\n",
    "            self.rotors[1].step()\n",
    "        \n",
    "        # Always step the rightmost rotor\n",
    "        self.rotors[0].step()\n",
    "    \n",
    "    def encode_char(self, char):\n",
    "        \"\"\"\n",
    "        Encode a single character through the Enigma machine\n",
    "        \n",
    "        Args:\n",
    "            char: Single uppercase letter A-Z\n",
    "            \n",
    "        Returns:\n",
    "            Encoded uppercase letter A-Z\n",
    "        \"\"\"\n",
    "        if not char.isalpha():\n",
    "            return char  # Return non-alphabetic characters unchanged\n",
    "        \n",
    "        char = char.upper()\n",
    "        char_index = ord(char) - ord('A')\n",
    "        \n",
    "        # Step rotors before encoding (historical behavior)\n",
    "        self.step_rotors()\n",
    "        \n",
    "        # Pass through rotors right to left\n",
    "        for rotor in self.rotors:\n",
    "            char_index = rotor.encode_forward(char_index)\n",
    "        \n",
    "        # Reflect\n",
    "        char_index = self.reflector.reflect(char_index)\n",
    "        \n",
    "        # Pass back through rotors left to right\n",
    "        for rotor in reversed(self.rotors):\n",
    "            char_index = rotor.encode_backward(char_index)\n",
    "        \n",
    "        return chr(char_index + ord('A'))\n",
    "    \n",
    "    def encode_text(self, text):\n",
    "        \"\"\"\n",
    "        Encode a string of text\n",
    "        \n",
    "        Args:\n",
    "            text: String to encode\n",
    "            \n",
    "        Returns:\n",
    "            Encoded string\n",
    "        \"\"\"\n",
    "        result = []\n",
    "        for char in text:\n",
    "            result.append(self.encode_char(char))\n",
    "        return ''.join(result)\n",
    "    \n",
    "    def get_rotor_positions(self):\n",
    "        \"\"\"Get current rotor positions as letters\"\"\"\n",
    "        return ''.join(chr(r.position + ord('A')) for r in self.rotors)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create Enigma machine with rotors I, II, III starting at AAA\n",
    "    enigma = EnigmaMachine(\n",
    "        rotor_types=('I', 'II', 'III'),\n",
    "        positions=(0, 0, 0),  # AAA\n",
    "        ring_settings=(0, 0, 0)  # AAA\n",
    "    )\n",
    "    \n",
    "    print(\"Enigma Machine Emulator\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Initial rotor positions: {enigma.get_rotor_positions()}\")\n",
    "    print()\n",
    "    \n",
    "    # Encode a message\n",
    "    plaintext = \"HELLO WORLD\"\n",
    "    print(f\"Plaintext:  {plaintext}\")\n",
    "    \n",
    "    ciphertext = enigma.encode_text(plaintext)\n",
    "    print(f\"Ciphertext: {ciphertext}\")\n",
    "    print(f\"Final rotor positions: {enigma.get_rotor_positions()}\")\n",
    "    print()\n",
    "    \n",
    "    # Decode the message (Enigma is reciprocal)\n",
    "    enigma_decode = EnigmaMachine(\n",
    "        rotor_types=('I', 'II', 'III'),\n",
    "        positions=(0, 0, 0),\n",
    "        ring_settings=(0, 0, 0)\n",
    "    )\n",
    "    \n",
    "    decoded = enigma_decode.encode_text(ciphertext)\n",
    "    print(f\"Decoded:    {decoded}\")\n",
    "    print(f\"Final rotor positions: {enigma_decode.get_rotor_positions()}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd574d64-d461-4b04-9795-01ed2dbc5e00",
   "metadata": {},
   "source": [
    "# This section asks the user for inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf1e4dc8-7fad-4c24-b1ef-fc1d07e4c804",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ENIGMA MACHINE EMULATOR\n",
      "======================================================================\n",
      "\n",
      "Available rotors: I, II, III, IV, V\n",
      "Enter rotor types (right, middle, left) separated by spaces\n",
      "Example: I II III\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Rotor types:  I II III\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter initial rotor positions (3 letters A-Z)\n",
      "Example: AAA or ABC\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Initial positions:  AAA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter text to encode (letters and spaces):\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Text:  There once was a man who lived In a blue house\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CONFIGURATION\n",
      "======================================================================\n",
      "Rotors (R→M→L):        I, II, III\n",
      "Initial Positions:     AAA\n",
      "Ring Settings:         AAA\n",
      "Reflector:             B\n",
      "\n",
      "======================================================================\n",
      "ENCODING PROCESS\n",
      "======================================================================\n",
      "Step   Input    Rotor Pos    Output  \n",
      "----------------------------------------------------------------------\n",
      "1      T        AAA          Z       \n",
      "2      H        BAA          P       \n",
      "3      E        CAA          T       \n",
      "4      R        DAA          Q       \n",
      "5      E        EAA          P       \n",
      "6      O        FAA          Q       \n",
      "7      N        GAA          F       \n",
      "8      C        HAA          N       \n",
      "9      E        IAA          G       \n",
      "10     W        JAA          N       \n",
      "11     A        KAA          J       \n",
      "12     S        LAA          H       \n",
      "13     A        MAA          G       \n",
      "14     M        NAA          V       \n",
      "15     A        OAA          N       \n",
      "16     N        PAA          Y       \n",
      "17     W        QAA          R       \n",
      "18     H        RBA          X       \n",
      "19     O        SBA          A       \n",
      "20     L        TBA          H       \n",
      "21     I        UBA          D       \n",
      "22     V        VBA          F       \n",
      "23     E        WBA          X       \n",
      "24     D        XBA          O       \n",
      "25     I        YBA          N       \n",
      "26     N        ZBA          Q       \n",
      "27     A        ABA          M       \n",
      "28     B        BBA          R       \n",
      "29     L        CBA          Z       \n",
      "30     U        DBA          O       \n",
      "31     E        EBA          A       \n",
      "32     H        FBA          M       \n",
      "33     O        GBA          P       \n",
      "34     U        HBA          C       \n",
      "35     S        IBA          X       \n",
      "36     E        JBA          L       \n",
      "\n",
      "======================================================================\n",
      "RESULTS\n",
      "======================================================================\n",
      "Plaintext:             THERE ONCE WAS A MAN WHO LIVED IN A BLUE HOUSE\n",
      "Ciphertext:            ZPTQP QFNG NJH G VNY RXA HDFXO NQ M RZOA MPCXL\n",
      "Final Rotor Positions: KBA\n",
      "Characters Encoded:    36\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION (Decoding)\n",
      "======================================================================\n",
      "Decoded Text:          THERE ONCE WAS A MAN WHO LIVED IN A BLUE HOUSE\n",
      "Match:                 ✓ SUCCESS\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "class Rotor:\n",
    "    \"\"\"Represents a single Enigma rotor with its wiring and position\"\"\"\n",
    "    \n",
    "    def __init__(self, wiring, notch, ring_setting=0, position=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            wiring: String of 26 letters representing the rotor's internal wiring\n",
    "            notch: Letter(s) where rotor causes next rotor to step\n",
    "            ring_setting: Ring setting (0-25, default 0 for 'A')\n",
    "            position: Initial rotor position (0-25, default 0 for 'A')\n",
    "        \"\"\"\n",
    "        self.wiring = wiring\n",
    "        self.notch = notch\n",
    "        self.ring_setting = ring_setting\n",
    "        self.position = position\n",
    "    \n",
    "    def encode_forward(self, char_index):\n",
    "        \"\"\"Encode character passing through rotor from right to left\"\"\"\n",
    "        # Adjust for rotor position and ring setting\n",
    "        shifted = (char_index + self.position - self.ring_setting) % 26\n",
    "        # Pass through wiring\n",
    "        encoded = ord(self.wiring[shifted]) - ord('A')\n",
    "        # Adjust back\n",
    "        return (encoded - self.position + self.ring_setting) % 26\n",
    "    \n",
    "    def encode_backward(self, char_index):\n",
    "        \"\"\"Encode character passing through rotor from left to right (after reflector)\"\"\"\n",
    "        # Adjust for rotor position and ring setting\n",
    "        shifted = (char_index + self.position - self.ring_setting) % 26\n",
    "        # Find inverse mapping in wiring\n",
    "        encoded = self.wiring.index(chr(shifted + ord('A')))\n",
    "        # Adjust back\n",
    "        return (encoded - self.position + self.ring_setting) % 26\n",
    "    \n",
    "    def is_at_notch(self):\n",
    "        \"\"\"Check if rotor is at notch position (will cause next rotor to turn)\"\"\"\n",
    "        return chr(self.position + ord('A')) in self.notch\n",
    "    \n",
    "    def step(self):\n",
    "        \"\"\"Rotate the rotor by one position\"\"\"\n",
    "        self.position = (self.position + 1) % 26\n",
    "\n",
    "\n",
    "class Reflector:\n",
    "    \"\"\"Represents the Enigma reflector\"\"\"\n",
    "    \n",
    "    def __init__(self, wiring):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            wiring: String of 26 letters representing reflector pairs\n",
    "        \"\"\"\n",
    "        self.wiring = wiring\n",
    "    \n",
    "    def reflect(self, char_index):\n",
    "        \"\"\"Reflect the character back through the rotors\"\"\"\n",
    "        return ord(self.wiring[char_index]) - ord('A')\n",
    "\n",
    "\n",
    "class EnigmaMachine:\n",
    "    \"\"\"Complete Enigma machine with 3 rotors and reflector\"\"\"\n",
    "    \n",
    "    # Historical rotor wirings (Enigma I)\n",
    "    ROTOR_I = \"EKMFLGDQVZNTOWYHXUSPAIBRCJ\"\n",
    "    ROTOR_II = \"AJDKSIRUXBLHWTMCQGZNPYFVOE\"\n",
    "    ROTOR_III = \"BDFHJLCPRTXVZNYEIWGAKMUSQO\"\n",
    "    ROTOR_IV = \"ESOVPZJAYQUIRHXLNFTGKDCMWB\"\n",
    "    ROTOR_V = \"VZBRGITYUPSDNHLXAWMJQOFECK\"\n",
    "    \n",
    "    # Reflector B (most commonly used)\n",
    "    REFLECTOR_B = \"YRUHQSLDPXNGOKMIEBFZCWVJAT\"\n",
    "    \n",
    "    # Notch positions for each rotor\n",
    "    NOTCHES = {\n",
    "        'I': 'Q',    # Rotor I turns rotor II when moving from Q to R\n",
    "        'II': 'E',   # Rotor II turns rotor III when moving from E to F\n",
    "        'III': 'V',  # Rotor III turns nothing (it's the leftmost)\n",
    "        'IV': 'J',\n",
    "        'V': 'Z'\n",
    "    }\n",
    "    \n",
    "    def __init__(self, rotor_types=('I', 'II', 'III'), \n",
    "                 positions=(0, 0, 0), ring_settings=(0, 0, 0)):\n",
    "        \"\"\"\n",
    "        Initialize Enigma machine\n",
    "        \n",
    "        Args:\n",
    "            rotor_types: Tuple of 3 rotor identifiers (rightmost, middle, leftmost)\n",
    "            positions: Starting positions for each rotor (0-25 for A-Z)\n",
    "            ring_settings: Ring settings for each rotor (0-25 for A-Z)\n",
    "        \"\"\"\n",
    "        rotor_wirings = {\n",
    "            'I': self.ROTOR_I,\n",
    "            'II': self.ROTOR_II,\n",
    "            'III': self.ROTOR_III,\n",
    "            'IV': self.ROTOR_IV,\n",
    "            'V': self.ROTOR_V\n",
    "        }\n",
    "        \n",
    "        # Create rotors (right, middle, left)\n",
    "        self.rotors = [\n",
    "            Rotor(rotor_wirings[rotor_types[0]], self.NOTCHES[rotor_types[0]], \n",
    "                  ring_settings[0], positions[0]),\n",
    "            Rotor(rotor_wirings[rotor_types[1]], self.NOTCHES[rotor_types[1]], \n",
    "                  ring_settings[1], positions[1]),\n",
    "            Rotor(rotor_wirings[rotor_types[2]], self.NOTCHES[rotor_types[2]], \n",
    "                  ring_settings[2], positions[2])\n",
    "        ]\n",
    "        \n",
    "        self.reflector = Reflector(self.REFLECTOR_B)\n",
    "    \n",
    "    def step_rotors(self):\n",
    "        \"\"\"\n",
    "        Step rotors according to Enigma stepping mechanism\n",
    "        Implements the double-stepping mechanism\n",
    "        \"\"\"\n",
    "        # Check if middle rotor is at notch (double-stepping)\n",
    "        if self.rotors[1].is_at_notch():\n",
    "            self.rotors[1].step()\n",
    "            self.rotors[2].step()\n",
    "        # Check if right rotor is at notch\n",
    "        elif self.rotors[0].is_at_notch():\n",
    "            self.rotors[1].step()\n",
    "        \n",
    "        # Always step the rightmost rotor\n",
    "        self.rotors[0].step()\n",
    "    \n",
    "    def encode_char(self, char):\n",
    "        \"\"\"\n",
    "        Encode a single character through the Enigma machine\n",
    "        \n",
    "        Args:\n",
    "            char: Single uppercase letter A-Z\n",
    "            \n",
    "        Returns:\n",
    "            Encoded uppercase letter A-Z\n",
    "        \"\"\"\n",
    "        if not char.isalpha():\n",
    "            return char  # Return non-alphabetic characters unchanged\n",
    "        \n",
    "        char = char.upper()\n",
    "        char_index = ord(char) - ord('A')\n",
    "        \n",
    "        # Step rotors before encoding (historical behavior)\n",
    "        self.step_rotors()\n",
    "        \n",
    "        # Pass through rotors right to left\n",
    "        for rotor in self.rotors:\n",
    "            char_index = rotor.encode_forward(char_index)\n",
    "        \n",
    "        # Reflect\n",
    "        char_index = self.reflector.reflect(char_index)\n",
    "        \n",
    "        # Pass back through rotors left to right\n",
    "        for rotor in reversed(self.rotors):\n",
    "            char_index = rotor.encode_backward(char_index)\n",
    "        \n",
    "        return chr(char_index + ord('A'))\n",
    "    \n",
    "    def encode_text(self, text):\n",
    "        \"\"\"\n",
    "        Encode a string of text\n",
    "        \n",
    "        Args:\n",
    "            text: String to encode\n",
    "            \n",
    "        Returns:\n",
    "            Encoded string\n",
    "        \"\"\"\n",
    "        result = []\n",
    "        for char in text:\n",
    "            result.append(self.encode_char(char))\n",
    "        return ''.join(result)\n",
    "    \n",
    "    def get_rotor_positions(self):\n",
    "        \"\"\"Get current rotor positions as letters\"\"\"\n",
    "        return ''.join(chr(r.position + ord('A')) for r in self.rotors)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\" * 70)\n",
    "    print(\"ENIGMA MACHINE EMULATOR\")\n",
    "    print(\"=\" * 70)\n",
    "    print()\n",
    "    \n",
    "    # Get rotor configuration from user\n",
    "    print(\"Available rotors: I, II, III, IV, V\")\n",
    "    print(\"Enter rotor types (right, middle, left) separated by spaces\")\n",
    "    print(\"Example: I II III\")\n",
    "    rotor_input = input(\"Rotor types: \").strip().upper().split()\n",
    "    \n",
    "    while len(rotor_input) != 3 or not all(r in ['I', 'II', 'III', 'IV', 'V'] for r in rotor_input):\n",
    "        print(\"Invalid input. Please enter exactly 3 rotors from: I, II, III, IV, V\")\n",
    "        rotor_input = input(\"Rotor types: \").strip().upper().split()\n",
    "    \n",
    "    rotor_types = tuple(rotor_input)\n",
    "    \n",
    "    # Get initial positions\n",
    "    print(\"\\nEnter initial rotor positions (3 letters A-Z)\")\n",
    "    print(\"Example: AAA or ABC\")\n",
    "    position_input = input(\"Initial positions: \").strip().upper()\n",
    "    \n",
    "    while len(position_input) != 3 or not all(c.isalpha() for c in position_input):\n",
    "        print(\"Invalid input. Please enter exactly 3 letters A-Z\")\n",
    "        position_input = input(\"Initial positions: \").strip().upper()\n",
    "    \n",
    "    positions = tuple(ord(c) - ord('A') for c in position_input)\n",
    "    \n",
    "    # Get text to encode\n",
    "    print(\"\\nEnter text to encode (letters and spaces):\")\n",
    "    plaintext = input(\"Text: \").strip().upper()\n",
    "    \n",
    "    # Create Enigma machine\n",
    "    enigma = EnigmaMachine(\n",
    "        rotor_types=rotor_types,\n",
    "        positions=positions,\n",
    "        ring_settings=(0, 0, 0)\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"CONFIGURATION\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Rotors (R→M→L):        {rotor_types[0]}, {rotor_types[1]}, {rotor_types[2]}\")\n",
    "    print(f\"Initial Positions:     {position_input}\")\n",
    "    print(f\"Ring Settings:         AAA\")\n",
    "    print(f\"Reflector:             B\")\n",
    "    \n",
    "    # Encode character by character and track positions\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"ENCODING PROCESS\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"{'Step':<6} {'Input':<8} {'Rotor Pos':<12} {'Output':<8}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Reset enigma for character-by-character encoding\n",
    "    enigma = EnigmaMachine(rotor_types=rotor_types, positions=positions, ring_settings=(0, 0, 0))\n",
    "    \n",
    "    ciphertext = []\n",
    "    step = 0\n",
    "    \n",
    "    for char in plaintext:\n",
    "        if char.isalpha():\n",
    "            step += 1\n",
    "            input_char = char\n",
    "            rotor_pos_before = enigma.get_rotor_positions()\n",
    "            output_char = enigma.encode_char(char)\n",
    "            ciphertext.append(output_char)\n",
    "            print(f\"{step:<6} {input_char:<8} {rotor_pos_before:<12} {output_char:<8}\")\n",
    "        else:\n",
    "            ciphertext.append(char)\n",
    "    \n",
    "    final_positions = enigma.get_rotor_positions()\n",
    "    ciphertext_str = ''.join(ciphertext)\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"RESULTS\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Plaintext:             {plaintext}\")\n",
    "    print(f\"Ciphertext:            {ciphertext_str}\")\n",
    "    print(f\"Final Rotor Positions: {final_positions}\")\n",
    "    print(f\"Characters Encoded:    {step}\")\n",
    "    \n",
    "    # Verification\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"VERIFICATION (Decoding)\")\n",
    "    print(\"=\" * 70)\n",
    "    enigma_decode = EnigmaMachine(rotor_types=rotor_types, positions=positions, ring_settings=(0, 0, 0))\n",
    "    decoded = enigma_decode.encode_text(ciphertext_str)\n",
    "    print(f\"Decoded Text:          {decoded}\")\n",
    "    print(f\"Match:                 {'✓ SUCCESS' if decoded == plaintext else '✗ FAILED'}\")\n",
    "    print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfa21d1-8278-4c05-a082-11657ed834f1",
   "metadata": {},
   "source": [
    "## This is attempt at a model mady by claud to predict the Rotors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61303b69-fd47-4a96-a33e-81fb25675eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "============================================================\n",
      "GENERATING DATASET FROM FILE\n",
      "============================================================\n",
      "Read 37231 letters from 'C:\\Users\\acool\\1 Capstone\\Engima-Capstone-main\\output_matrix_no_punctuation.txt'\n",
      "\n",
      "Generating 5000 training samples...\n",
      "Rotor order: ['III', 'II', 'I'] (Left-Middle-Right)\n",
      "Initial positions: [0, 0, 0] (AAA)\n",
      "  Generated 1000/5000 samples\n",
      "  Generated 2000/5000 samples\n",
      "  Generated 3000/5000 samples\n",
      "  Generated 4000/5000 samples\n",
      "  Generated 5000/5000 samples\n",
      "\n",
      "Training samples: 4000\n",
      "Validation samples: 1000\n",
      "\n",
      "============================================================\n",
      "CREATING MODEL\n",
      "============================================================\n",
      "Total parameters: 1,001,742\n",
      "\n",
      "============================================================\n",
      "TRAINING MODEL\n",
      "============================================================\n",
      "\n",
      "Epoch 1/20\n",
      "Train Loss: 0.1179\n",
      "Train Acc - R1: 99.17%, R2: 99.33%, R3: 99.25%\n",
      "Val Loss: 0.0000\n",
      "Val Acc - R1: 100.00%, R2: 100.00%, R3: 100.00%\n",
      "✓ Saved best model with avg accuracy: 100.00%\n",
      "\n",
      "Epoch 2/20\n",
      "Train Loss: 0.0000\n",
      "Train Acc - R1: 100.00%, R2: 100.00%, R3: 100.00%\n",
      "Val Loss: 0.0000\n",
      "Val Acc - R1: 100.00%, R2: 100.00%, R3: 100.00%\n",
      "\n",
      "Epoch 3/20\n",
      "Train Loss: 0.0000\n",
      "Train Acc - R1: 100.00%, R2: 100.00%, R3: 100.00%\n",
      "Val Loss: 0.0000\n",
      "Val Acc - R1: 100.00%, R2: 100.00%, R3: 100.00%\n",
      "\n",
      "Epoch 4/20\n",
      "Train Loss: 0.0000\n",
      "Train Acc - R1: 100.00%, R2: 100.00%, R3: 100.00%\n",
      "Val Loss: 0.0000\n",
      "Val Acc - R1: 100.00%, R2: 100.00%, R3: 100.00%\n",
      "\n",
      "Epoch 5/20\n",
      "Train Loss: 0.0000\n",
      "Train Acc - R1: 100.00%, R2: 100.00%, R3: 100.00%\n",
      "Val Loss: 0.0000\n",
      "Val Acc - R1: 100.00%, R2: 100.00%, R3: 100.00%\n",
      "\n",
      "Epoch 6/20\n",
      "Train Loss: 0.0000\n",
      "Train Acc - R1: 100.00%, R2: 100.00%, R3: 100.00%\n",
      "Val Loss: 0.0000\n",
      "Val Acc - R1: 100.00%, R2: 100.00%, R3: 100.00%\n",
      "\n",
      "Epoch 7/20\n",
      "Train Loss: 0.0000\n",
      "Train Acc - R1: 100.00%, R2: 100.00%, R3: 100.00%\n",
      "Val Loss: 0.0000\n",
      "Val Acc - R1: 100.00%, R2: 100.00%, R3: 100.00%\n",
      "\n",
      "Epoch 8/20\n",
      "Train Loss: 0.0000\n",
      "Train Acc - R1: 100.00%, R2: 100.00%, R3: 100.00%\n",
      "Val Loss: 0.0000\n",
      "Val Acc - R1: 100.00%, R2: 100.00%, R3: 100.00%\n",
      "\n",
      "Epoch 9/20\n",
      "Train Loss: 0.0000\n",
      "Train Acc - R1: 100.00%, R2: 100.00%, R3: 100.00%\n",
      "Val Loss: 0.0000\n",
      "Val Acc - R1: 100.00%, R2: 100.00%, R3: 100.00%\n",
      "\n",
      "Epoch 10/20\n",
      "Train Loss: 0.0000\n",
      "Train Acc - R1: 100.00%, R2: 100.00%, R3: 100.00%\n",
      "Val Loss: 0.0000\n",
      "Val Acc - R1: 100.00%, R2: 100.00%, R3: 100.00%\n",
      "\n",
      "Epoch 11/20\n",
      "Train Loss: 0.0000\n",
      "Train Acc - R1: 100.00%, R2: 100.00%, R3: 100.00%\n",
      "Val Loss: 0.0000\n",
      "Val Acc - R1: 100.00%, R2: 100.00%, R3: 100.00%\n",
      "\n",
      "Epoch 12/20\n",
      "Train Loss: 0.0000\n",
      "Train Acc - R1: 100.00%, R2: 100.00%, R3: 100.00%\n",
      "Val Loss: 0.0000\n",
      "Val Acc - R1: 100.00%, R2: 100.00%, R3: 100.00%\n",
      "\n",
      "Epoch 13/20\n",
      "Train Loss: 0.0000\n",
      "Train Acc - R1: 100.00%, R2: 100.00%, R3: 100.00%\n",
      "Val Loss: 0.0000\n",
      "Val Acc - R1: 100.00%, R2: 100.00%, R3: 100.00%\n",
      "\n",
      "Epoch 14/20\n",
      "Train Loss: 0.0000\n",
      "Train Acc - R1: 100.00%, R2: 100.00%, R3: 100.00%\n",
      "Val Loss: 0.0000\n",
      "Val Acc - R1: 100.00%, R2: 100.00%, R3: 100.00%\n",
      "\n",
      "Epoch 15/20\n",
      "Train Loss: 0.0000\n",
      "Train Acc - R1: 100.00%, R2: 100.00%, R3: 100.00%\n",
      "Val Loss: 0.0000\n",
      "Val Acc - R1: 100.00%, R2: 100.00%, R3: 100.00%\n",
      "\n",
      "Epoch 16/20\n",
      "Train Loss: 0.0000\n",
      "Train Acc - R1: 100.00%, R2: 100.00%, R3: 100.00%\n",
      "Val Loss: 0.0000\n",
      "Val Acc - R1: 100.00%, R2: 100.00%, R3: 100.00%\n",
      "\n",
      "Epoch 17/20\n",
      "Train Loss: 0.0000\n",
      "Train Acc - R1: 100.00%, R2: 100.00%, R3: 100.00%\n",
      "Val Loss: 0.0000\n",
      "Val Acc - R1: 100.00%, R2: 100.00%, R3: 100.00%\n",
      "\n",
      "Epoch 18/20\n",
      "Train Loss: 0.0000\n",
      "Train Acc - R1: 100.00%, R2: 100.00%, R3: 100.00%\n",
      "Val Loss: 0.0000\n",
      "Val Acc - R1: 100.00%, R2: 100.00%, R3: 100.00%\n",
      "\n",
      "Epoch 19/20\n",
      "Train Loss: 0.0000\n",
      "Train Acc - R1: 100.00%, R2: 100.00%, R3: 100.00%\n",
      "Val Loss: 0.0000\n",
      "Val Acc - R1: 100.00%, R2: 100.00%, R3: 100.00%\n",
      "\n",
      "Epoch 20/20\n",
      "Train Loss: 0.0000\n",
      "Train Acc - R1: 100.00%, R2: 100.00%, R3: 100.00%\n",
      "Val Loss: 0.0000\n",
      "Val Acc - R1: 100.00%, R2: 100.00%, R3: 100.00%\n",
      "\n",
      "============================================================\n",
      "TESTING PREDICTIONS\n",
      "============================================================\n",
      "\n",
      "Test Configuration:\n",
      "  Rotors: ['III', 'II', 'I'] (Left-Middle-Right)\n",
      "  True positions: [0, 0, 0] (AAA)\n",
      "  Plaintext: ACCORDINGTOALLKNOWNLAWSOFAVIATIONTHEREISNOWAYABEES...\n",
      "  Ciphertext: BREMEVPMYALSEYQEZVYFMJLAAXJVCJZTHGQZMQKWFFDIBNYCAX...\n",
      "\n",
      "Predictions:\n",
      "  Rotor 1: 0 (A) - Confidence: 100.0%\n",
      "  Rotor 2: 0 (A) - Confidence: 100.0%\n",
      "  Rotor 3: 0 (A) - Confidence: 100.0%\n",
      "\n",
      "Accuracy:\n",
      "  Rotor 1: ✓ CORRECT\n",
      "  Rotor 2: ✓ CORRECT\n",
      "  Rotor 3: ✓ CORRECT\n",
      "\n",
      "============================================================\n",
      "TRAINING COMPLETE\n",
      "============================================================\n",
      "Model saved as: best_enigma_model.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import string\n",
    "import os\n",
    "\n",
    "# Force file paths to be relative to the script location (works in both Python script & Jupyter)\n",
    "try:\n",
    "    BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "except NameError:\n",
    "    BASE_DIR = os.getcwd()\n",
    "\n",
    "INPUT_TEXT_FILE = os.path.join(BASE_DIR, 'output_matrix_no_punctuation.txt')\n",
    "\n",
    "\n",
    "\n",
    "# Training configuration\n",
    "MESSAGE_LENGTH = 100  # How many characters to use per training sample\n",
    "NUM_TRAINING_SAMPLES = 5000  # Number of encrypted samples to generate\n",
    "\n",
    "# ============================================================================\n",
    "# ENIGMA SIMULATOR (Simplified - no plugboard)\n",
    "# ============================================================================\n",
    "class SimpleEnigma:\n",
    "    \"\"\"Simplified Enigma machine simulator\"\"\"\n",
    "    \n",
    "    # Historical rotor wirings (I-V)\n",
    "    ROTORS = {\n",
    "        'I':   'EKMFLGDQVZNTOWYHXUSPAIBRCJ',\n",
    "        'II':  'AJDKSIRUXBLHWTMCQGZNPYFVOE',\n",
    "        'III': 'BDFHJLCPRTXVZNYEIWGAKMUSQO',\n",
    "        'IV':  'ESOVPZJAYQUIRHXLNFTGKDCMWB',\n",
    "        'V':   'VZBRGITYUPSDNHLXAWMJQOFECK'\n",
    "    }\n",
    "    \n",
    "    # Notch positions (when rotor steps the next one)\n",
    "    NOTCHES = {\n",
    "        'I': 'Q', 'II': 'E', 'III': 'V', 'IV': 'J', 'V': 'Z'\n",
    "    }\n",
    "    \n",
    "    REFLECTOR = 'YRUHQSLDPXNGOKMIEBFZCWVJAT'\n",
    "    \n",
    "    def __init__(self, rotors, positions):\n",
    "        \"\"\"\n",
    "        rotors: list of 3 rotor names, e.g., ['III', 'II', 'I']\n",
    "        positions: list of 3 starting positions (0-25)\n",
    "        \"\"\"\n",
    "        self.rotors = [self.ROTORS[r] for r in rotors]\n",
    "        self.rotor_names = rotors\n",
    "        self.positions = positions.copy()\n",
    "        self.initial_positions = positions.copy()\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset rotor positions to initial state\"\"\"\n",
    "        self.positions = self.initial_positions.copy()\n",
    "    \n",
    "    def step_rotors(self):\n",
    "        \"\"\"Advance rotors according to Enigma stepping rules\"\"\"\n",
    "        # Check for double-stepping of middle rotor\n",
    "        if self.rotor_at_notch(1):\n",
    "            self.positions[1] = (self.positions[1] + 1) % 26\n",
    "            self.positions[2] = (self.positions[2] + 1) % 26\n",
    "        elif self.rotor_at_notch(0):\n",
    "            self.positions[1] = (self.positions[1] + 1) % 26\n",
    "        \n",
    "        # Always step the rightmost rotor\n",
    "        self.positions[0] = (self.positions[0] + 1) % 26\n",
    "    \n",
    "    def rotor_at_notch(self, rotor_index):\n",
    "        \"\"\"Check if rotor is at its notch position\"\"\"\n",
    "        notch = self.NOTCHES[self.rotor_names[rotor_index]]\n",
    "        notch_pos = ord(notch) - ord('A')\n",
    "        return self.positions[rotor_index] == notch_pos\n",
    "    \n",
    "    def encrypt_char(self, char):\n",
    "        \"\"\"Encrypt a single character\"\"\"\n",
    "        if char not in string.ascii_uppercase:\n",
    "            return char\n",
    "        \n",
    "        # Step rotors before encryption\n",
    "        self.step_rotors()\n",
    "        \n",
    "        # Convert char to number (A=0, B=1, ...)\n",
    "        pos = ord(char) - ord('A')\n",
    "        \n",
    "        # Forward through rotors (right to left)\n",
    "        for i in range(3):\n",
    "            pos = (pos + self.positions[i]) % 26\n",
    "            pos = ord(self.rotors[i][pos]) - ord('A')\n",
    "            pos = (pos - self.positions[i]) % 26\n",
    "        \n",
    "        # Through reflector\n",
    "        pos = ord(self.REFLECTOR[pos]) - ord('A')\n",
    "        \n",
    "        # Backward through rotors (left to right)\n",
    "        for i in range(2, -1, -1):\n",
    "            pos = (pos + self.positions[i]) % 26\n",
    "            pos = self.rotors[i].index(chr(pos + ord('A')))\n",
    "            pos = (pos - self.positions[i]) % 26\n",
    "        \n",
    "        return chr(pos + ord('A'))\n",
    "    \n",
    "    def encrypt(self, text):\n",
    "        \"\"\"Encrypt a full message\"\"\"\n",
    "        self.reset()\n",
    "        result = []\n",
    "        for char in text.upper():\n",
    "            result.append(self.encrypt_char(char))\n",
    "        return ''.join(result)\n",
    "\n",
    "# ============================================================================\n",
    "# FILE READING AND DATA PREPARATION\n",
    "# ============================================================================\n",
    "def read_text_from_file(filename):\n",
    "    \"\"\"\n",
    "    Read text from a file with one letter per line\n",
    "    Returns a string of uppercase letters only\n",
    "    \"\"\"\n",
    "    if not os.path.exists(filename):\n",
    "        raise FileNotFoundError(f\"Input file '{filename}' not found!\")\n",
    "    \n",
    "    letters = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip().upper()\n",
    "            # Only keep valid letters\n",
    "            for char in line:\n",
    "                if char in string.ascii_uppercase:\n",
    "                    letters.append(char)\n",
    "    \n",
    "    text = ''.join(letters)\n",
    "    print(f\"Read {len(text)} letters from '{filename}'\")\n",
    "    return text\n",
    "\n",
    "def generate_dataset_from_file(filename, rotor_order, initial_positions, \n",
    "                                num_samples=5000, message_length=100):\n",
    "    \"\"\"\n",
    "    Generate training dataset by encrypting text from file\n",
    "    \n",
    "    Args:\n",
    "        filename: Path to input text file\n",
    "        rotor_order: List of 3 rotor names (e.g., ['III', 'II', 'I'])\n",
    "        initial_positions: List of 3 starting positions (e.g., [0, 0, 0] for AAA)\n",
    "        num_samples: Number of training samples to generate\n",
    "        message_length: Length of each training sample\n",
    "    \"\"\"\n",
    "    # Read plaintext from file\n",
    "    full_plaintext = read_text_from_file(filename)\n",
    "    \n",
    "    if len(full_plaintext) < message_length:\n",
    "        raise ValueError(f\"File contains only {len(full_plaintext)} letters, but need at least {message_length}\")\n",
    "    \n",
    "    data = []\n",
    "    print(f\"\\nGenerating {num_samples} training samples...\")\n",
    "    print(f\"Rotor order: {rotor_order} (Left-Middle-Right)\")\n",
    "    print(f\"Initial positions: {initial_positions} ({chr(initial_positions[0]+65)}{chr(initial_positions[1]+65)}{chr(initial_positions[2]+65)})\")\n",
    "    \n",
    "    # Create enigma machine with fixed configuration\n",
    "    enigma = SimpleEnigma(rotor_order, initial_positions)\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        if (i + 1) % 1000 == 0:\n",
    "            print(f\"  Generated {i + 1}/{num_samples} samples\")\n",
    "        \n",
    "        # Extract a chunk of text from the file\n",
    "        # Use modulo to wrap around if we need more samples than file length allows\n",
    "        start_idx = (i * message_length) % (len(full_plaintext) - message_length)\n",
    "        plaintext = full_plaintext[start_idx:start_idx + message_length]\n",
    "        \n",
    "        # Encrypt the plaintext\n",
    "        ciphertext = enigma.encrypt(plaintext)\n",
    "        \n",
    "        data.append({\n",
    "            'ciphertext': ciphertext,\n",
    "            'plaintext': plaintext,\n",
    "            'rotors': rotor_order,\n",
    "            'positions': initial_positions\n",
    "        })\n",
    "    \n",
    "    return data\n",
    "\n",
    "# ============================================================================\n",
    "# PYTORCH DATASET\n",
    "# ============================================================================\n",
    "class EnigmaDataset(Dataset):\n",
    "    \"\"\"PyTorch dataset for Enigma encrypted messages\"\"\"\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        \n",
    "        # Convert ciphertext to one-hot encoded tensor\n",
    "        ciphertext_encoded = self.encode_text(item['ciphertext'])\n",
    "        \n",
    "        # Convert positions to tensor (3 values, each 0-25)\n",
    "        positions = torch.tensor(item['positions'], dtype=torch.long)\n",
    "        \n",
    "        return ciphertext_encoded, positions\n",
    "    \n",
    "    @staticmethod\n",
    "    def encode_text(text):\n",
    "        \"\"\"Convert text to one-hot encoded tensor\"\"\"\n",
    "        # Create tensor of shape (seq_len, 26)\n",
    "        encoded = torch.zeros(len(text), 26)\n",
    "        for i, char in enumerate(text):\n",
    "            if char in string.ascii_uppercase:\n",
    "                encoded[i, ord(char) - ord('A')] = 1\n",
    "        return encoded\n",
    "\n",
    "# ============================================================================\n",
    "# NEURAL NETWORK MODEL\n",
    "# ============================================================================\n",
    "class EnigmaRotorClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN-based model to predict rotor positions from encrypted text\n",
    "    \n",
    "    OPTIMIZATION NOTES:\n",
    "    - To change the number of convolutional layers, add/remove conv layers\n",
    "    - To change the number of nodes in conv layers, modify the channel numbers\n",
    "      (currently: 64 -> 128 -> 256)\n",
    "    - To change the number of fully connected layers, add/remove fc layers\n",
    "    - To change the number of nodes in FC layers, modify hidden_dim parameter\n",
    "      (currently: 256)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, message_length=100, hidden_dim=256):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            message_length: Length of input message\n",
    "            hidden_dim: Number of nodes in fully connected layers\n",
    "                       *** CHANGE THIS TO ADJUST FC LAYER SIZE ***\n",
    "        \"\"\"\n",
    "        super(EnigmaRotorClassifier, self).__init__()\n",
    "        \n",
    "        # ====================================================================\n",
    "        # CONVOLUTIONAL LAYERS - MODIFY NUMBER OF LAYERS AND NODES HERE\n",
    "        # ====================================================================\n",
    "        # Current architecture: 3 conv layers with 64, 128, 256 channels\n",
    "        # To add more layers: add self.conv4, self.batch_norm4, etc.\n",
    "        # To change nodes: modify the channel numbers (e.g., 64 -> 128)\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(26, 64, kernel_size=3, padding=1)      # *** 64 nodes ***\n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=3, padding=1)     # *** 128 nodes ***\n",
    "        self.conv3 = nn.Conv1d(128, 256, kernel_size=3, padding=1)    # *** 256 nodes ***\n",
    "        \n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # Calculate flattened size after convolutions\n",
    "        # NOTE: If you change number of conv layers, adjust the divisor\n",
    "        # Currently: 3 conv layers with pooling = divide by 2^3 = 8\n",
    "        conv_output_size = message_length // 8 * 256  # 256 is last conv layer size\n",
    "        \n",
    "        # ====================================================================\n",
    "        # FULLY CONNECTED LAYERS - MODIFY NUMBER OF LAYERS AND NODES HERE\n",
    "        # ====================================================================\n",
    "        # Current architecture: 2 FC layers with hidden_dim nodes each\n",
    "        # To add more layers: add self.fc3, self.fc4, etc. and update forward()\n",
    "        # To change nodes: modify hidden_dim parameter when creating model\n",
    "        \n",
    "        self.fc1 = nn.Linear(conv_output_size, hidden_dim)  # *** hidden_dim nodes ***\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)        # *** hidden_dim nodes ***\n",
    "        \n",
    "        # Three output heads (one for each rotor position, 26 classes each)\n",
    "        self.rotor1_head = nn.Linear(hidden_dim, 26)\n",
    "        self.rotor2_head = nn.Linear(hidden_dim, 26)\n",
    "        self.rotor3_head = nn.Linear(hidden_dim, 26)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(64)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(128)\n",
    "        self.batch_norm3 = nn.BatchNorm1d(256)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len, 26)\n",
    "        # Conv1d expects (batch_size, channels, seq_len)\n",
    "        x = x.transpose(1, 2)\n",
    "        \n",
    "        # ====================================================================\n",
    "        # FORWARD PASS THROUGH CONVOLUTIONAL LAYERS\n",
    "        # If you add/remove conv layers, update this section\n",
    "        # ====================================================================\n",
    "        x = self.relu(self.batch_norm1(self.conv1(x)))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.relu(self.batch_norm2(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.relu(self.batch_norm3(self.conv3(x)))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # ====================================================================\n",
    "        # FORWARD PASS THROUGH FULLY CONNECTED LAYERS\n",
    "        # If you add/remove FC layers, update this section\n",
    "        # ====================================================================\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        \n",
    "        # Output predictions for each rotor\n",
    "        rotor1_out = self.rotor1_head(x)\n",
    "        rotor2_out = self.rotor2_head(x)\n",
    "        rotor3_out = self.rotor3_head(x)\n",
    "        \n",
    "        return rotor1_out, rotor2_out, rotor3_out\n",
    "\n",
    "# ============================================================================\n",
    "# TRAINING FUNCTIONS\n",
    "# ============================================================================\n",
    "def train_model(model, train_loader, val_loader, num_epochs=20, device='cuda'):\n",
    "    \"\"\"Train the Enigma rotor classifier\"\"\"\n",
    "    \n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = [0, 0, 0]\n",
    "        train_total = 0\n",
    "        \n",
    "        for batch_idx, (ciphertext, positions) in enumerate(train_loader):\n",
    "            ciphertext = ciphertext.to(device)\n",
    "            positions = positions.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            out1, out2, out3 = model(ciphertext)\n",
    "            \n",
    "            # Calculate loss for each rotor\n",
    "            loss1 = criterion(out1, positions[:, 0])\n",
    "            loss2 = criterion(out2, positions[:, 1])\n",
    "            loss3 = criterion(out3, positions[:, 2])\n",
    "            loss = loss1 + loss2 + loss3\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            _, pred1 = torch.max(out1, 1)\n",
    "            _, pred2 = torch.max(out2, 1)\n",
    "            _, pred3 = torch.max(out3, 1)\n",
    "            \n",
    "            train_correct[0] += (pred1 == positions[:, 0]).sum().item()\n",
    "            train_correct[1] += (pred2 == positions[:, 1]).sum().item()\n",
    "            train_correct[2] += (pred3 == positions[:, 2]).sum().item()\n",
    "            train_total += positions.size(0)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = [0, 0, 0]\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for ciphertext, positions in val_loader:\n",
    "                ciphertext = ciphertext.to(device)\n",
    "                positions = positions.to(device)\n",
    "                \n",
    "                out1, out2, out3 = model(ciphertext)\n",
    "                \n",
    "                loss1 = criterion(out1, positions[:, 0])\n",
    "                loss2 = criterion(out2, positions[:, 1])\n",
    "                loss3 = criterion(out3, positions[:, 2])\n",
    "                loss = loss1 + loss2 + loss3\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                _, pred1 = torch.max(out1, 1)\n",
    "                _, pred2 = torch.max(out2, 1)\n",
    "                _, pred3 = torch.max(out3, 1)\n",
    "                \n",
    "                val_correct[0] += (pred1 == positions[:, 0]).sum().item()\n",
    "                val_correct[1] += (pred2 == positions[:, 1]).sum().item()\n",
    "                val_correct[2] += (pred3 == positions[:, 2]).sum().item()\n",
    "                val_total += positions.size(0)\n",
    "        \n",
    "        # Calculate accuracies\n",
    "        train_acc = [(c / train_total) * 100 for c in train_correct]\n",
    "        val_acc = [(c / val_total) * 100 for c in val_correct]\n",
    "        avg_val_acc = sum(val_acc) / 3\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
    "        print(f'Train Loss: {train_loss/len(train_loader):.4f}')\n",
    "        print(f'Train Acc - R1: {train_acc[0]:.2f}%, R2: {train_acc[1]:.2f}%, R3: {train_acc[2]:.2f}%')\n",
    "        print(f'Val Loss: {val_loss/len(val_loader):.4f}')\n",
    "        print(f'Val Acc - R1: {val_acc[0]:.2f}%, R2: {val_acc[1]:.2f}%, R3: {val_acc[2]:.2f}%')\n",
    "        \n",
    "        # Save best model\n",
    "        if avg_val_acc > best_val_acc:\n",
    "            best_val_acc = avg_val_acc\n",
    "            torch.save(model.state_dict(), 'best_enigma_model.pth')\n",
    "            print(f'✓ Saved best model with avg accuracy: {avg_val_acc:.2f}%')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# ============================================================================\n",
    "# PREDICTION AND TESTING\n",
    "# ============================================================================\n",
    "def predict_positions(model, ciphertext, device='cuda'):\n",
    "    \"\"\"Predict rotor positions from encrypted message\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Encode ciphertext\n",
    "    encoded = EnigmaDataset.encode_text(ciphertext).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        out1, out2, out3 = model(encoded)\n",
    "        \n",
    "        _, pred1 = torch.max(out1, 1)\n",
    "        _, pred2 = torch.max(out2, 1)\n",
    "        _, pred3 = torch.max(out3, 1)\n",
    "        \n",
    "        # Get confidence scores\n",
    "        probs1 = torch.softmax(out1, dim=1)[0]\n",
    "        probs2 = torch.softmax(out2, dim=1)[0]\n",
    "        probs3 = torch.softmax(out3, dim=1)[0]\n",
    "        \n",
    "        confidence1 = probs1[pred1].item() * 100\n",
    "        confidence2 = probs2[pred2].item() * 100\n",
    "        confidence3 = probs3[pred3].item() * 100\n",
    "    \n",
    "    predictions = [pred1.item(), pred2.item(), pred3.item()]\n",
    "    confidences = [confidence1, confidence2, confidence3]\n",
    "    \n",
    "    return predictions, confidences\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "if __name__ == '__main__':\n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'Using device: {device}\\n')\n",
    "    \n",
    "    # Generate dataset from file\n",
    "    print('=' * 60)\n",
    "    print('GENERATING DATASET FROM FILE')\n",
    "    print('=' * 60)\n",
    "    \n",
    "    try:\n",
    "        dataset = generate_dataset_from_file(\n",
    "            filename=INPUT_TEXT_FILE,\n",
    "            rotor_order=DEFAULT_ROTOR_ORDER,\n",
    "            initial_positions=DEFAULT_POSITIONS,\n",
    "            num_samples=NUM_TRAINING_SAMPLES,\n",
    "            message_length=MESSAGE_LENGTH\n",
    "        )\n",
    "    except FileNotFoundError:\n",
    "        print(f\"\\nERROR: Input file '{INPUT_TEXT_FILE}' not found!\")\n",
    "        print(\"Please create this file with one letter per line.\")\n",
    "        print(\"Example content:\")\n",
    "        print(\"A\")\n",
    "        print(\"B\")\n",
    "        print(\"C\")\n",
    "        print(\"...\")\n",
    "        exit(1)\n",
    "    \n",
    "    # Split into train/val\n",
    "    split_idx = int(0.8 * len(dataset))\n",
    "    train_data = dataset[:split_idx]\n",
    "    val_data = dataset[split_idx:]\n",
    "    \n",
    "    train_dataset = EnigmaDataset(train_data)\n",
    "    val_dataset = EnigmaDataset(val_data)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    print(f'\\nTraining samples: {len(train_data)}')\n",
    "    print(f'Validation samples: {len(val_data)}')\n",
    "    \n",
    "    # Create model\n",
    "    print('\\n' + '=' * 60)\n",
    "    print('CREATING MODEL')\n",
    "    print('=' * 60)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # MODEL CREATION - CHANGE hidden_dim TO ADJUST FC LAYER SIZE\n",
    "    # ========================================================================\n",
    "    model = EnigmaRotorClassifier(\n",
    "        message_length=MESSAGE_LENGTH,\n",
    "        hidden_dim=256  # *** CHANGE THIS TO MODIFY FC LAYER SIZE ***\n",
    "    )\n",
    "    \n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f'Total parameters: {total_params:,}')\n",
    "    \n",
    "    # Train model\n",
    "    print('\\n' + '=' * 60)\n",
    "    print('TRAINING MODEL')\n",
    "    print('=' * 60)\n",
    "    model = train_model(model, train_loader, val_loader, num_epochs=20, device=device)\n",
    "    \n",
    "    # Test predictions\n",
    "    print('\\n' + '=' * 60)\n",
    "    print('TESTING PREDICTIONS')\n",
    "    print('=' * 60)\n",
    "    \n",
    "    # Create test message using the same configuration\n",
    "    enigma = SimpleEnigma(DEFAULT_ROTOR_ORDER, DEFAULT_POSITIONS)\n",
    "    test_plaintext = dataset[0]['plaintext']  # Use first sample as test\n",
    "    test_ciphertext = enigma.encrypt(test_plaintext)\n",
    "    \n",
    "    print(f'\\nTest Configuration:')\n",
    "    print(f'  Rotors: {DEFAULT_ROTOR_ORDER} (Left-Middle-Right)')\n",
    "    print(f'  True positions: {DEFAULT_POSITIONS} ({chr(DEFAULT_POSITIONS[0]+65)}{chr(DEFAULT_POSITIONS[1]+65)}{chr(DEFAULT_POSITIONS[2]+65)})')\n",
    "    print(f'  Plaintext: {test_plaintext[:50]}...')\n",
    "    print(f'  Ciphertext: {test_ciphertext[:50]}...')\n",
    "    \n",
    "    predictions, confidences = predict_positions(model, test_ciphertext, device)\n",
    "    \n",
    "    print(f'\\nPredictions:')\n",
    "    print(f'  Rotor 1: {predictions[0]} ({chr(predictions[0]+65)}) - Confidence: {confidences[0]:.1f}%')\n",
    "    print(f'  Rotor 2: {predictions[1]} ({chr(predictions[1]+65)}) - Confidence: {confidences[1]:.1f}%')\n",
    "    print(f'  Rotor 3: {predictions[2]} ({chr(predictions[2]+65)}) - Confidence: {confidences[2]:.1f}%')\n",
    "    \n",
    "    print(f'\\nAccuracy:')\n",
    "    print(f'  Rotor 1: {\"✓ CORRECT\" if predictions[0] == DEFAULT_POSITIONS[0] else \"✗ INCORRECT\"}')\n",
    "    print(f'  Rotor 2: {\"✓ CORRECT\" if predictions[1] == DEFAULT_POSITIONS[1] else \"✗ INCORRECT\"}')\n",
    "    print(f'  Rotor 3: {\"✓ CORRECT\" if predictions[2] == DEFAULT_POSITIONS[2] else \"✗ INCORRECT\"}')\n",
    "    \n",
    "    print('\\n' + '=' * 60)\n",
    "    print('TRAINING COMPLETE')\n",
    "    print('=' * 60)\n",
    "    print('Model saved as: best_enigma_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a788b32-3534-49e8-bbfa-96c050f1b9da",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f7df1ca-f21f-4de1-8fd5-cc6e52f7281e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "============================================================\n",
      "GENERATING DATASET\n",
      "============================================================\n",
      "Generating 5000 training samples...\n",
      "  Generated 1000/5000 samples\n",
      "  Generated 2000/5000 samples\n",
      "  Generated 3000/5000 samples\n",
      "  Generated 4000/5000 samples\n",
      "  Generated 5000/5000 samples\n",
      "\n",
      "Training samples: 4000\n",
      "Validation samples: 1000\n",
      "\n",
      "============================================================\n",
      "CREATING MODEL\n",
      "============================================================\n",
      "Total parameters: 1,001,742\n",
      "\n",
      "============================================================\n",
      "TRAINING MODEL\n",
      "============================================================\n",
      "\n",
      "Epoch 1/20\n",
      "Train Loss: 9.8075\n",
      "Train Acc - R1: 4.15%, R2: 4.23%, R3: 4.17%\n",
      "Val Loss: 9.7748\n",
      "Val Acc - R1: 3.40%, R2: 3.40%, R3: 4.00%\n",
      "✓ Saved best model with avg accuracy: 3.60%\n",
      "\n",
      "Epoch 2/20\n",
      "Train Loss: 9.7746\n",
      "Train Acc - R1: 4.35%, R2: 4.17%, R3: 4.38%\n",
      "Val Loss: 9.7742\n",
      "Val Acc - R1: 3.40%, R2: 3.40%, R3: 4.00%\n",
      "\n",
      "Epoch 3/20\n",
      "Train Loss: 9.7726\n",
      "Train Acc - R1: 4.28%, R2: 4.30%, R3: 4.08%\n",
      "Val Loss: 9.7751\n",
      "Val Acc - R1: 3.40%, R2: 2.90%, R3: 3.70%\n",
      "\n",
      "Epoch 4/20\n",
      "Train Loss: 9.7717\n",
      "Train Acc - R1: 4.15%, R2: 4.42%, R3: 4.47%\n",
      "Val Loss: 9.7752\n",
      "Val Acc - R1: 3.40%, R2: 2.90%, R3: 3.70%\n",
      "\n",
      "Epoch 5/20\n",
      "Train Loss: 9.7679\n",
      "Train Acc - R1: 4.35%, R2: 4.15%, R3: 4.00%\n",
      "Val Loss: 9.7783\n",
      "Val Acc - R1: 3.50%, R2: 3.30%, R3: 3.90%\n",
      "\n",
      "Epoch 6/20\n",
      "Train Loss: 9.7509\n",
      "Train Acc - R1: 4.35%, R2: 4.40%, R3: 4.67%\n",
      "Val Loss: 9.7767\n",
      "Val Acc - R1: 3.30%, R2: 3.20%, R3: 4.00%\n",
      "\n",
      "Epoch 7/20\n",
      "Train Loss: 9.7430\n",
      "Train Acc - R1: 4.35%, R2: 4.28%, R3: 4.72%\n",
      "Val Loss: 9.7782\n",
      "Val Acc - R1: 3.50%, R2: 3.20%, R3: 3.70%\n",
      "\n",
      "Epoch 8/20\n",
      "Train Loss: 9.7375\n",
      "Train Acc - R1: 4.32%, R2: 3.95%, R3: 4.72%\n",
      "Val Loss: 9.7820\n",
      "Val Acc - R1: 3.60%, R2: 3.20%, R3: 3.50%\n",
      "\n",
      "Epoch 9/20\n",
      "Train Loss: 9.7302\n",
      "Train Acc - R1: 4.40%, R2: 4.67%, R3: 4.88%\n",
      "Val Loss: 9.7804\n",
      "Val Acc - R1: 3.60%, R2: 3.00%, R3: 3.70%\n",
      "\n",
      "Epoch 10/20\n",
      "Train Loss: 9.7229\n",
      "Train Acc - R1: 4.42%, R2: 4.45%, R3: 4.85%\n",
      "Val Loss: 9.7815\n",
      "Val Acc - R1: 3.60%, R2: 3.00%, R3: 3.50%\n",
      "\n",
      "Epoch 11/20\n",
      "Train Loss: 9.7158\n",
      "Train Acc - R1: 4.52%, R2: 4.38%, R3: 5.20%\n",
      "Val Loss: 9.7820\n",
      "Val Acc - R1: 3.60%, R2: 3.20%, R3: 3.50%\n",
      "\n",
      "Epoch 12/20\n",
      "Train Loss: 9.7247\n",
      "Train Acc - R1: 4.52%, R2: 4.45%, R3: 4.75%\n",
      "Val Loss: 9.7816\n",
      "Val Acc - R1: 3.60%, R2: 3.00%, R3: 3.50%\n",
      "\n",
      "Epoch 13/20\n",
      "Train Loss: 9.7226\n",
      "Train Acc - R1: 4.42%, R2: 4.50%, R3: 4.92%\n",
      "Val Loss: 9.7832\n",
      "Val Acc - R1: 3.60%, R2: 3.00%, R3: 3.60%\n",
      "\n",
      "Epoch 14/20\n",
      "Train Loss: 9.7174\n",
      "Train Acc - R1: 4.60%, R2: 4.62%, R3: 4.80%\n",
      "Val Loss: 9.7832\n",
      "Val Acc - R1: 3.60%, R2: 3.00%, R3: 3.60%\n",
      "\n",
      "Epoch 15/20\n",
      "Train Loss: 9.7201\n",
      "Train Acc - R1: 4.52%, R2: 4.83%, R3: 5.15%\n",
      "Val Loss: 9.7830\n",
      "Val Acc - R1: 3.60%, R2: 3.00%, R3: 3.50%\n",
      "\n",
      "Epoch 16/20\n",
      "Train Loss: 9.7186\n",
      "Train Acc - R1: 4.40%, R2: 4.65%, R3: 4.98%\n",
      "Val Loss: 9.7832\n",
      "Val Acc - R1: 3.60%, R2: 3.00%, R3: 3.60%\n",
      "\n",
      "Epoch 17/20\n",
      "Train Loss: 9.7185\n",
      "Train Acc - R1: 4.58%, R2: 4.60%, R3: 5.00%\n",
      "Val Loss: 9.7833\n",
      "Val Acc - R1: 3.60%, R2: 3.00%, R3: 3.60%\n",
      "\n",
      "Epoch 18/20\n",
      "Train Loss: 9.7147\n",
      "Train Acc - R1: 4.62%, R2: 4.65%, R3: 5.20%\n",
      "Val Loss: 9.7830\n",
      "Val Acc - R1: 3.60%, R2: 3.00%, R3: 3.50%\n",
      "\n",
      "Epoch 19/20\n",
      "Train Loss: 9.7164\n",
      "Train Acc - R1: 4.67%, R2: 4.50%, R3: 5.00%\n",
      "Val Loss: 9.7832\n",
      "Val Acc - R1: 3.60%, R2: 3.00%, R3: 3.60%\n",
      "\n",
      "Epoch 20/20\n",
      "Train Loss: 9.7224\n",
      "Train Acc - R1: 4.47%, R2: 4.62%, R3: 4.98%\n",
      "Val Loss: 9.7832\n",
      "Val Acc - R1: 3.60%, R2: 3.00%, R3: 3.60%\n",
      "\n",
      "============================================================\n",
      "TESTING PREDICTIONS\n",
      "============================================================\n",
      "\n",
      "Test Configuration:\n",
      "  Rotors: ['I', 'II', 'III']\n",
      "  True positions: [5, 12, 20] (F, M, U)\n",
      "  Plaintext: SPNHFASRDIENDILAYTPNFDTNUTCFUKFQIAUMWPOLLINOIPAAUT...\n",
      "  Ciphertext: HGPSHFEIECUTHGERSFCKOXSGXGZUTGEVNBJCXXMPCHCQPJVXMS...\n",
      "\n",
      "Predictions:\n",
      "  Rotor 1: 19 (T) - Confidence: 4.3%\n",
      "  Rotor 2: 16 (Q) - Confidence: 4.3%\n",
      "  Rotor 3: 14 (O) - Confidence: 4.2%\n",
      "\n",
      "Accuracy:\n",
      "  Rotor 1: ✗ INCORRECT\n",
      "  Rotor 2: ✗ INCORRECT\n",
      "  Rotor 3: ✗ INCORRECT\n",
      "\n",
      "============================================================\n",
      "TRAINING COMPLETE\n",
      "============================================================\n",
      "Model saved as: best_enigma_model.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "\n",
    "# ============================================================================\n",
    "# ENIGMA SIMULATOR (Simplified - no plugboard)\n",
    "# ============================================================================\n",
    "\n",
    "class SimpleEnigma:\n",
    "    \"\"\"Simplified Enigma machine simulator for demonstration\"\"\"\n",
    "    \n",
    "    # Historical rotor wirings (I-V)\n",
    "    ROTORS = {\n",
    "        'I':   'EKMFLGDQVZNTOWYHXUSPAIBRCJ',\n",
    "        'II':  'AJDKSIRUXBLHWTMCQGZNPYFVOE',\n",
    "        'III': 'BDFHJLCPRTXVZNYEIWGAKMUSQO',\n",
    "        'IV':  'ESOVPZJAYQUIRHXLNFTGKDCMWB',\n",
    "        'V':   'VZBRGITYUPSDNHLXAWMJQOFECK'\n",
    "    }\n",
    "    \n",
    "    # Notch positions (when rotor steps the next one)\n",
    "    NOTCHES = {\n",
    "        'I': 'Q', 'II': 'E', 'III': 'V', 'IV': 'J', 'V': 'Z'\n",
    "    }\n",
    "    \n",
    "    REFLECTOR = 'YRUHQSLDPXNGOKMIEBFZCWVJAT'\n",
    "    \n",
    "    def __init__(self, rotors, positions):\n",
    "        \"\"\"\n",
    "        rotors: list of 3 rotor names, e.g., ['I', 'II', 'III']\n",
    "        positions: list of 3 starting positions (0-25)\n",
    "        \"\"\"\n",
    "        self.rotors = [self.ROTORS[r] for r in rotors]\n",
    "        self.rotor_names = rotors\n",
    "        self.positions = positions.copy()\n",
    "        self.initial_positions = positions.copy()\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset rotor positions to initial state\"\"\"\n",
    "        self.positions = self.initial_positions.copy()\n",
    "    \n",
    "    def step_rotors(self):\n",
    "        \"\"\"Advance rotors according to Enigma stepping rules\"\"\"\n",
    "        # Check for double-stepping of middle rotor\n",
    "        if self.rotor_at_notch(1):\n",
    "            self.positions[1] = (self.positions[1] + 1) % 26\n",
    "            self.positions[2] = (self.positions[2] + 1) % 26\n",
    "        elif self.rotor_at_notch(0):\n",
    "            self.positions[1] = (self.positions[1] + 1) % 26\n",
    "        \n",
    "        # Always step the rightmost rotor\n",
    "        self.positions[0] = (self.positions[0] + 1) % 26\n",
    "    \n",
    "    def rotor_at_notch(self, rotor_index):\n",
    "        \"\"\"Check if rotor is at its notch position\"\"\"\n",
    "        notch = self.NOTCHES[self.rotor_names[rotor_index]]\n",
    "        notch_pos = ord(notch) - ord('A')\n",
    "        return self.positions[rotor_index] == notch_pos\n",
    "    \n",
    "    def encrypt_char(self, char):\n",
    "        \"\"\"Encrypt a single character\"\"\"\n",
    "        if char not in string.ascii_uppercase:\n",
    "            return char\n",
    "        \n",
    "        # Step rotors before encryption\n",
    "        self.step_rotors()\n",
    "        \n",
    "        # Convert char to number (A=0, B=1, ...)\n",
    "        pos = ord(char) - ord('A')\n",
    "        \n",
    "        # Forward through rotors (right to left)\n",
    "        for i in range(3):\n",
    "            pos = (pos + self.positions[i]) % 26\n",
    "            pos = ord(self.rotors[i][pos]) - ord('A')\n",
    "            pos = (pos - self.positions[i]) % 26\n",
    "        \n",
    "        # Through reflector\n",
    "        pos = ord(self.REFLECTOR[pos]) - ord('A')\n",
    "        \n",
    "        # Backward through rotors (left to right)\n",
    "        for i in range(2, -1, -1):\n",
    "            pos = (pos + self.positions[i]) % 26\n",
    "            pos = self.rotors[i].index(chr(pos + ord('A')))\n",
    "            pos = (pos - self.positions[i]) % 26\n",
    "        \n",
    "        return chr(pos + ord('A'))\n",
    "    \n",
    "    def encrypt(self, text):\n",
    "        \"\"\"Encrypt a full message\"\"\"\n",
    "        self.reset()\n",
    "        result = []\n",
    "        for char in text.upper():\n",
    "            result.append(self.encrypt_char(char))\n",
    "        return ''.join(result)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# DATA GENERATION\n",
    "# ============================================================================\n",
    "\n",
    "def generate_random_text(length=100):\n",
    "    \"\"\"Generate random English-like text\"\"\"\n",
    "    # Use more common letters for realistic distribution\n",
    "    common_letters = 'ETAOINSHRDLCUMWFGYPBVKJXQZ'\n",
    "    weights = [12.7, 9.1, 8.2, 7.5, 7.0, 6.7, 6.3, 6.1, 6.0, 5.9,\n",
    "               4.3, 4.0, 2.8, 2.8, 2.4, 2.4, 2.2, 2.0, 2.0, 1.9,\n",
    "               1.5, 1.0, 0.15, 0.15, 0.10, 0.07]\n",
    "    \n",
    "    return ''.join(random.choices(common_letters, weights=weights, k=length))\n",
    "\n",
    "\n",
    "def generate_dataset(num_samples=5000, message_length=100):\n",
    "    \"\"\"Generate training dataset with encrypted messages and rotor positions\"\"\"\n",
    "    rotor_names = ['I', 'II', 'III', 'IV', 'V']\n",
    "    data = []\n",
    "    \n",
    "    print(f\"Generating {num_samples} training samples...\")\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        if (i + 1) % 1000 == 0:\n",
    "            print(f\"  Generated {i + 1}/{num_samples} samples\")\n",
    "        \n",
    "        # Random rotor configuration\n",
    "        rotors = random.sample(rotor_names, 3)\n",
    "        positions = [random.randint(0, 25) for _ in range(3)]\n",
    "        \n",
    "        # Generate and encrypt message\n",
    "        plaintext = generate_random_text(message_length)\n",
    "        enigma = SimpleEnigma(rotors, positions)\n",
    "        ciphertext = enigma.encrypt(plaintext)\n",
    "        \n",
    "        data.append({\n",
    "            'ciphertext': ciphertext,\n",
    "            'plaintext': plaintext,\n",
    "            'rotors': rotors,\n",
    "            'positions': positions\n",
    "        })\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# PYTORCH DATASET\n",
    "# ============================================================================\n",
    "\n",
    "class EnigmaDataset(Dataset):\n",
    "    \"\"\"PyTorch dataset for Enigma encrypted messages\"\"\"\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        \n",
    "        # Convert ciphertext to one-hot encoded tensor\n",
    "        ciphertext_encoded = self.encode_text(item['ciphertext'])\n",
    "        \n",
    "        # Convert positions to tensor (3 values, each 0-25)\n",
    "        positions = torch.tensor(item['positions'], dtype=torch.long)\n",
    "        \n",
    "        return ciphertext_encoded, positions\n",
    "    \n",
    "    @staticmethod\n",
    "    def encode_text(text):\n",
    "        \"\"\"Convert text to one-hot encoded tensor\"\"\"\n",
    "        # Create tensor of shape (seq_len, 26)\n",
    "        encoded = torch.zeros(len(text), 26)\n",
    "        for i, char in enumerate(text):\n",
    "            if char in string.ascii_uppercase:\n",
    "                encoded[i, ord(char) - ord('A')] = 1\n",
    "        return encoded\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# NEURAL NETWORK MODEL\n",
    "# ============================================================================\n",
    "\n",
    "class EnigmaRotorClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN-based model to predict rotor positions from encrypted text\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, message_length=100, embedding_dim=128, hidden_dim=256):\n",
    "        super(EnigmaRotorClassifier, self).__init__()\n",
    "        \n",
    "        # Convolutional layers to extract patterns from ciphertext\n",
    "        self.conv1 = nn.Conv1d(26, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(128, 256, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # Calculate flattened size after convolutions\n",
    "        conv_output_size = message_length // 8 * 256\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(conv_output_size, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        \n",
    "        # Three output heads (one for each rotor position, 26 classes each)\n",
    "        self.rotor1_head = nn.Linear(hidden_dim, 26)\n",
    "        self.rotor2_head = nn.Linear(hidden_dim, 26)\n",
    "        self.rotor3_head = nn.Linear(hidden_dim, 26)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(64)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(128)\n",
    "        self.batch_norm3 = nn.BatchNorm1d(256)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len, 26)\n",
    "        # Conv1d expects (batch_size, channels, seq_len)\n",
    "        x = x.transpose(1, 2)\n",
    "        \n",
    "        # Convolutional feature extraction\n",
    "        x = self.relu(self.batch_norm1(self.conv1(x)))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.relu(self.batch_norm2(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.relu(self.batch_norm3(self.conv3(x)))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        \n",
    "        # Output predictions for each rotor\n",
    "        rotor1_out = self.rotor1_head(x)\n",
    "        rotor2_out = self.rotor2_head(x)\n",
    "        rotor3_out = self.rotor3_head(x)\n",
    "        \n",
    "        return rotor1_out, rotor2_out, rotor3_out\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# TRAINING FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs=20, device='cuda'):\n",
    "    \"\"\"Train the Enigma rotor classifier\"\"\"\n",
    "    \n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = [0, 0, 0]\n",
    "        train_total = 0\n",
    "        \n",
    "        for batch_idx, (ciphertext, positions) in enumerate(train_loader):\n",
    "            ciphertext = ciphertext.to(device)\n",
    "            positions = positions.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            out1, out2, out3 = model(ciphertext)\n",
    "            \n",
    "            # Calculate loss for each rotor\n",
    "            loss1 = criterion(out1, positions[:, 0])\n",
    "            loss2 = criterion(out2, positions[:, 1])\n",
    "            loss3 = criterion(out3, positions[:, 2])\n",
    "            loss = loss1 + loss2 + loss3\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            _, pred1 = torch.max(out1, 1)\n",
    "            _, pred2 = torch.max(out2, 1)\n",
    "            _, pred3 = torch.max(out3, 1)\n",
    "            \n",
    "            train_correct[0] += (pred1 == positions[:, 0]).sum().item()\n",
    "            train_correct[1] += (pred2 == positions[:, 1]).sum().item()\n",
    "            train_correct[2] += (pred3 == positions[:, 2]).sum().item()\n",
    "            train_total += positions.size(0)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = [0, 0, 0]\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for ciphertext, positions in val_loader:\n",
    "                ciphertext = ciphertext.to(device)\n",
    "                positions = positions.to(device)\n",
    "                \n",
    "                out1, out2, out3 = model(ciphertext)\n",
    "                \n",
    "                loss1 = criterion(out1, positions[:, 0])\n",
    "                loss2 = criterion(out2, positions[:, 1])\n",
    "                loss3 = criterion(out3, positions[:, 2])\n",
    "                loss = loss1 + loss2 + loss3\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                _, pred1 = torch.max(out1, 1)\n",
    "                _, pred2 = torch.max(out2, 1)\n",
    "                _, pred3 = torch.max(out3, 1)\n",
    "                \n",
    "                val_correct[0] += (pred1 == positions[:, 0]).sum().item()\n",
    "                val_correct[1] += (pred2 == positions[:, 1]).sum().item()\n",
    "                val_correct[2] += (pred3 == positions[:, 2]).sum().item()\n",
    "                val_total += positions.size(0)\n",
    "        \n",
    "        # Calculate accuracies\n",
    "        train_acc = [(c / train_total) * 100 for c in train_correct]\n",
    "        val_acc = [(c / val_total) * 100 for c in val_correct]\n",
    "        avg_val_acc = sum(val_acc) / 3\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
    "        print(f'Train Loss: {train_loss/len(train_loader):.4f}')\n",
    "        print(f'Train Acc - R1: {train_acc[0]:.2f}%, R2: {train_acc[1]:.2f}%, R3: {train_acc[2]:.2f}%')\n",
    "        print(f'Val Loss: {val_loss/len(val_loader):.4f}')\n",
    "        print(f'Val Acc - R1: {val_acc[0]:.2f}%, R2: {val_acc[1]:.2f}%, R3: {val_acc[2]:.2f}%')\n",
    "        \n",
    "        # Save best model\n",
    "        if avg_val_acc > best_val_acc:\n",
    "            best_val_acc = avg_val_acc\n",
    "            torch.save(model.state_dict(), 'best_enigma_model.pth')\n",
    "            print(f'✓ Saved best model with avg accuracy: {avg_val_acc:.2f}%')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# PREDICTION AND TESTING\n",
    "# ============================================================================\n",
    "\n",
    "def predict_positions(model, ciphertext, device='cuda'):\n",
    "    \"\"\"Predict rotor positions from encrypted message\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Encode ciphertext\n",
    "    encoded = EnigmaDataset.encode_text(ciphertext).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        out1, out2, out3 = model(encoded)\n",
    "        \n",
    "        _, pred1 = torch.max(out1, 1)\n",
    "        _, pred2 = torch.max(out2, 1)\n",
    "        _, pred3 = torch.max(out3, 1)\n",
    "        \n",
    "        # Get confidence scores\n",
    "        probs1 = torch.softmax(out1, dim=1)[0]\n",
    "        probs2 = torch.softmax(out2, dim=1)[0]\n",
    "        probs3 = torch.softmax(out3, dim=1)[0]\n",
    "        \n",
    "        confidence1 = probs1[pred1].item() * 100\n",
    "        confidence2 = probs2[pred2].item() * 100\n",
    "        confidence3 = probs3[pred3].item() * 100\n",
    "    \n",
    "    predictions = [pred1.item(), pred2.item(), pred3.item()]\n",
    "    confidences = [confidence1, confidence2, confidence3]\n",
    "    \n",
    "    return predictions, confidences\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'Using device: {device}\\n')\n",
    "    \n",
    "    # Generate dataset\n",
    "    print('=' * 60)\n",
    "    print('GENERATING DATASET')\n",
    "    print('=' * 60)\n",
    "    dataset = generate_dataset(num_samples=5000, message_length=100)\n",
    "    \n",
    "    # Split into train/val\n",
    "    split_idx = int(0.8 * len(dataset))\n",
    "    train_data = dataset[:split_idx]\n",
    "    val_data = dataset[split_idx:]\n",
    "    \n",
    "    train_dataset = EnigmaDataset(train_data)\n",
    "    val_dataset = EnigmaDataset(val_data)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    print(f'\\nTraining samples: {len(train_data)}')\n",
    "    print(f'Validation samples: {len(val_data)}')\n",
    "    \n",
    "    # Create model\n",
    "    print('\\n' + '=' * 60)\n",
    "    print('CREATING MODEL')\n",
    "    print('=' * 60)\n",
    "    model = EnigmaRotorClassifier(message_length=100)\n",
    "    \n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f'Total parameters: {total_params:,}')\n",
    "    \n",
    "    # Train model\n",
    "    print('\\n' + '=' * 60)\n",
    "    print('TRAINING MODEL')\n",
    "    print('=' * 60)\n",
    "    model = train_model(model, train_loader, val_loader, num_epochs=20, device=device)\n",
    "    \n",
    "    # Test predictions\n",
    "    print('\\n' + '=' * 60)\n",
    "    print('TESTING PREDICTIONS')\n",
    "    print('=' * 60)\n",
    "    \n",
    "    # Create test message\n",
    "    test_rotors = ['I', 'II', 'III']\n",
    "    test_positions = [5, 12, 20]  # F, M, U\n",
    "    enigma = SimpleEnigma(test_rotors, test_positions)\n",
    "    test_plaintext = generate_random_text(100)\n",
    "    test_ciphertext = enigma.encrypt(test_plaintext)\n",
    "    \n",
    "    print(f'\\nTest Configuration:')\n",
    "    print(f'  Rotors: {test_rotors}')\n",
    "    print(f'  True positions: {test_positions} ({chr(test_positions[0]+65)}, {chr(test_positions[1]+65)}, {chr(test_positions[2]+65)})')\n",
    "    print(f'  Plaintext: {test_plaintext[:50]}...')\n",
    "    print(f'  Ciphertext: {test_ciphertext[:50]}...')\n",
    "    \n",
    "    predictions, confidences = predict_positions(model, test_ciphertext, device)\n",
    "    \n",
    "    print(f'\\nPredictions:')\n",
    "    print(f'  Rotor 1: {predictions[0]} ({chr(predictions[0]+65)}) - Confidence: {confidences[0]:.1f}%')\n",
    "    print(f'  Rotor 2: {predictions[1]} ({chr(predictions[1]+65)}) - Confidence: {confidences[1]:.1f}%')\n",
    "    print(f'  Rotor 3: {predictions[2]} ({chr(predictions[2]+65)}) - Confidence: {confidences[2]:.1f}%')\n",
    "    \n",
    "    print(f'\\nAccuracy:')\n",
    "    print(f'  Rotor 1: {\"✓ CORRECT\" if predictions[0] == test_positions[0] else \"✗ INCORRECT\"}')\n",
    "    print(f'  Rotor 2: {\"✓ CORRECT\" if predictions[1] == test_positions[1] else \"✗ INCORRECT\"}')\n",
    "    print(f'  Rotor 3: {\"✓ CORRECT\" if predictions[2] == test_positions[2] else \"✗ INCORRECT\"}')\n",
    "    \n",
    "    print('\\n' + '=' * 60)\n",
    "    print('TRAINING COMPLETE')\n",
    "    print('=' * 60)\n",
    "    print('Model saved as: best_enigma_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514d6520-040b-4fc6-8e9f-4b10e39df489",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
